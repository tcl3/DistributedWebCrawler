version: '3.4'

services:
  managerapi:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlermanagerapi
    container_name: 'managerapi'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ManagerAPI/Dockerfile
    ports:
      - 58081:80
    environment:
        RABBITMQ_HOSTNAME: "rabbitmq"
        #RABBITMQ_PORT: "5672"
        RABBITMQ_USERNAME: "crawler"
        RABBITMQ_PASSWORD: "test"
        DEV_MODE: "false"
    networks:
       - rabbitmq_net
    volumes:
      - log_storage:/app/Logs/
    depends_on:
      rabbitmq:
        condition: service_healthy

  # This is an example of how to run multiple crawler components in a single container. 
  #
  # Be sure to uncomment the service in docker-override.yml if using this
  #components:
  #  image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
  #  container_name: 'components'
  #  build:
  #    context: .
  #    dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
  #  environment:
  #    COMPONENTAPI_ROLE: "scheduler,ingester,parser,robotsdownloader"
  #    RABBITMQ_HOSTNAME: "rabbitmq"
  #    #RABBITMQ_PORT: "5672"
  #    RABBITMQ_USERNAME: "crawler"
  #    RABBITMQ_PASSWORD: "test"
  #    REDIS_CONNECTIONSTRING: "redis:6379"
  #  networks:
  #     - rabbitmq_net
  #     - redis_net
  #  volumes:
  #    - log_storage:/app/Logs/
  #  depends_on:
  #    rabbitmq:
  #      condition: service_healthy
  #    redis:
  #      condition: service_healthy

  scheduler:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
    container_name: 'scheduler'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
    environment:
      COMPONENTAPI_ROLE: "scheduler" 
      RABBITMQ_HOSTNAME: "rabbitmq"
      #RABBITMQ_PORT: "5672"
      RABBITMQ_USERNAME: "crawler"
      RABBITMQ_PASSWORD: "test"
      REDIS_CONNECTIONSTRING: "redis:6379"
    networks:
        - redis_net
        - rabbitmq_net
    volumes:
      - log_storage:/app/Logs/
    depends_on:
      rabbitmq:
        condition: service_healthy

  ingester:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
    container_name: 'ingester'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
    environment:
      COMPONENTAPI_ROLE: "ingester"
      RABBITMQ_HOSTNAME: "rabbitmq"
      #RABBITMQ_PORT: "5672"
      RABBITMQ_USERNAME: "crawler"
      RABBITMQ_PASSWORD: "test"
      REDIS_CONNECTIONSTRING: "redis:6379"
    networks:
       - rabbitmq_net
       - redis_net
    volumes:
      - log_storage:/app/Logs/
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy

  parser:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
    container_name: 'parser'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
    environment:
      COMPONENTAPI_ROLE: "parser"
      RABBITMQ_HOSTNAME: "rabbitmq"
      #RABBITMQ_PORT: "5672"
      RABBITMQ_USERNAME: "crawler"
      RABBITMQ_PASSWORD: "test"
      REDIS_CONNECTIONSTRING: "redis:6379"
    networks:
       - rabbitmq_net
       - redis_net
    volumes:
      - log_storage:/app/Logs/
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy

  robotsdownloader:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
    container_name: 'robotsdownloader'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
    environment:
      COMPONENTAPI_ROLE: "robotsdownloader"
      RABBITMQ_HOSTNAME: "rabbitmq"
      #RABBITMQ_PORT: "5672"
      RABBITMQ_USERNAME: "crawler"
      RABBITMQ_PASSWORD: "test"
      REDIS_CONNECTIONSTRING: "redis:6379"
    networks:
       - rabbitmq_net
       - redis_net
    volumes:
      - log_storage:/app/Logs/
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: 'rabbitmq'
    ports:
      #- 127.0.0.1:5672:5672
      - 15672:15672
    environment:
        RABBITMQ_PID_FILE: "/var/lib/rabbitmq/mnesia/rabbitmq"
    volumes:
      - ./rabbitmq-config/:/etc/rabbitmq/
      - ~/.docker-conf/rabbitmq/data/:/var/lib/rabbitmq/
      - ~/.docker-conf/rabbitmq/log/:/var/log/rabbitmq/
    networks:
      - rabbitmq_net
    healthcheck:
        test: ["CMD", "wget", "-nv -t1 --spider", "http://localhost:15672"]
        interval: 10s
        timeout: 10s
        retries: 10

  redis:
    image: "redis:alpine"
    container_name: 'redis'
    ports:
     - 6379:6379
    volumes:
      - ~/.docker-conf/redis/data:/var/lib/redis
      - ~/.docker-conf/redis/redis.conf:/usr/local/etc/redis/redis.conf
    environment:
      - REDIS_REPLICATION_MODE=master
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30
    networks:
      - rabbitmq_net
  
  # Redis management GUI - for testing purposes
  redisinsight:
    image: redislabs/redisinsight:latest
    container_name: 'redisinsight'
    ports:
      - 8001:8001
    networks:
      - rabbitmq_net
    volumes:
      - ~/.docker-conf/redisinight:/db

  loki:
      image: grafana/loki:latest
      hostname: loki
      ports:
        - "3100:3100"
      command: -config.file=/etc/loki/local-config.yaml
      networks:
        - loki

  promtail:
    image: grafana/promtail:latest
    hostname: pomtail
    volumes:      
      - log_storage:/var/log/
      - ./pomtail-config/config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml
    networks:
      - loki

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana:/var/lib/grafana
      #- C:/docker-config/grafana/:/etc/grafana/
    networks:
      - loki

volumes:
  log_storage:
  grafana:

networks:
  rabbitmq_net:
    driver: bridge
  redis_net:
    driver: bridge
  loki:
    driver: bridge
