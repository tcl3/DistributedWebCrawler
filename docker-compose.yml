version: '3.4'

services:
  managerapi:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlermanagerapi
    container_name: 'managerapi'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ManagerAPI/Dockerfile
    ports:
      - 58081:80
    environment:
        RABBITMQ_HOSTNAME: "rabbitmq"
        #RABBITMQ_PORT: "5672"
        RABBITMQ_USERNAME: "crawler"
        RABBITMQ_PASSWORD: "test"
    networks:
       - rabbitmq_net
    depends_on:
      rabbitmq:
        condition: service_healthy

  # This is an example of how to run multiple crawler components in a single container. 
  #
  # Be sure to uncomment the service in docker-override.yml if using this
  #components:
  #  image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
  #  container_name: 'components'
  #  build:
  #    context: .
  #    dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
  #  environment:
  #    COMPONENTAPI_ROLE: "scheduler,ingester,parser" 
  #    RABBITMQ_HOSTNAME: "rabbitmq"
  #    #RABBITMQ_PORT: "5672"
  #    RABBITMQ_USERNAME: "crawler"
  #    RABBITMQ_PASSWORD: "test"
  #  networks:
  #     - rabbitmq_net
  #  depends_on:
  #    rabbitmq:
  #      condition: service_healthy

  scheduler:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
    container_name: 'scheduler'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
    environment:
      COMPONENTAPI_ROLE: "scheduler" 
      RABBITMQ_HOSTNAME: "rabbitmq"
      #RABBITMQ_PORT: "5672"
      RABBITMQ_USERNAME: "crawler"
      RABBITMQ_PASSWORD: "test"
    networks:
       - rabbitmq_net
    depends_on:
      rabbitmq:
        condition: service_healthy

  ingester:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
    container_name: 'ingester'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
    environment:
      COMPONENTAPI_ROLE: "ingester"
      RABBITMQ_HOSTNAME: "rabbitmq"
      #RABBITMQ_PORT: "5672"
      RABBITMQ_USERNAME: "crawler"
      RABBITMQ_PASSWORD: "test"
    networks:
       - rabbitmq_net
    depends_on:
      rabbitmq:
        condition: service_healthy

  parser:
    image: ${DOCKER_REGISTRY-}distributedwebcrawlercomponentapi
    container_name: 'parser'
    build:
      context: .
      dockerfile: DistributedWebCrawler.ComponentAPI/Dockerfile
    environment:
      COMPONENTAPI_ROLE: "parser"
      RABBITMQ_HOSTNAME: "rabbitmq"
      #RABBITMQ_PORT: "5672"
      RABBITMQ_USERNAME: "crawler"
      RABBITMQ_PASSWORD: "test"
    networks:
       - rabbitmq_net
    depends_on:
      rabbitmq:
        condition: service_healthy

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: 'rabbitmq'
    ports:
      #- 127.0.0.1:5672:5672
      - 127.0.0.1:15672:15672
    environment:
        RABBITMQ_PID_FILE: "/var/lib/rabbitmq/mnesia/rabbitmq"
    volumes:
      - ./rabbitmq-config/:/etc/rabbitmq/
      - ~/.docker-conf/rabbitmq/data/:/var/lib/rabbitmq/
      - ~/.docker-conf/rabbitmq/log/:/var/log/rabbitmq/
    networks:
        - rabbitmq_net
    healthcheck:
        test: ["CMD", "wget", "-nv -t1 --spider", "http://localhost:15672"]
        interval: 10s
        timeout: 10s
        retries: 10

networks:
  rabbitmq_net:
    driver: bridge
